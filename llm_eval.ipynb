{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce97452-b09b-4218-aac7-fb2fefaf4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Using cached GPUtil-1.4.0-py3-none-any.whl\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.3.0+cu121)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting optimum\n",
      "  Using cached optimum-1.21.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Collecting coloredlogs (from optimum)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (4.25.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.11/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (0.2.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "Using cached datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "Using cached accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "Using cached optimum-1.21.2-py3-none-any.whl (424 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Installing collected packages: gputil, xxhash, safetensors, requests, humanfriendly, coloredlogs, transformers, datasets, accelerate, optimum\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "arxiv 2.1.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.32.1 coloredlogs-15.0.1 datasets-2.20.0 gputil-1.4.0 humanfriendly-10.0 optimum-1.21.2 requests-2.32.3 safetensors-0.4.3 transformers-4.42.4 xxhash-3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gputil transformers datasets torch datasets accelerate optimum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d4f0733-8c22-43ed-a51b-00a75265bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ID: 0\n",
      "Name: NVIDIA L40\n",
      "Total Memory: 46068.0MB\n",
      "Free Memory: 45373.0MB\n",
      "Used Memory: 1.0MB\n",
      "GPU Load: 0.0%\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "\n",
    "gpus = GPUtil.getGPUs()\n",
    "for gpu in gpus:\n",
    "    print(f\"GPU ID: {gpu.id}\")\n",
    "    print(f\"Name: {gpu.name}\")\n",
    "    print(f\"Total Memory: {gpu.memoryTotal}MB\")\n",
    "    print(f\"Free Memory: {gpu.memoryFree}MB\")\n",
    "    print(f\"Used Memory: {gpu.memoryUsed}MB\")\n",
    "    print(f\"GPU Load: {gpu.load * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a44479c-1127-4aa9-a084-8445946f296d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630de960622b4f58bdba670ea6ed59c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e226dc-119e-4e72-a359-3c7a97fd0f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 09:28:12.834277: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-14 09:28:12.880772: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-14 09:28:13.827756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7c02db2cf34d12a8cbab2225d5a45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    'text-generation', \n",
    "    model=model_id, \n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.bfloat16,\n",
    "    },\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c587344-aa17-46a6-8f46-8e332bd69242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(text_generator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a54786-ff02-4575-adb7-1422b242e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper funtion that generates a response given prompt\n",
    "def invoke_response(prompt):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "    ]\n",
    "        \n",
    "    terminators = [\n",
    "        pipe.tokenizer.eos_token_id,\n",
    "        pipe.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    pipe.model.generation_config.pad_token_id = pipe.tokenizer.pad_token_id\n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=pipe.tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    response = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17149902-80b7-4335-b9b4-84b2e368fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple choice\n",
    "def generate_response(activity, input_text, next_sentence_start):\n",
    "    \n",
    "    prompt_template_finish = f\"You are an AI assistant. Based on the activity and the input provided, finish the next sentence. \\\n",
    "    Only generate the finished part of the sentence. \\\n",
    "    \\n\\nContext: {activity}\\n\\n \\\n",
    "    Input: {input_text}\\n\\n \\\n",
    "    Start of the next sentence: {next_sentence_start}\\n\\n \\\n",
    "    Finish the sentence: \"\n",
    "    \n",
    "    # Helper funtion that generates a response given prompt\n",
    "    return invoke_response(prompt_template_finish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319d0456-c652-4364-9c1a-37e4a3a1b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_choice_response(activity, input_text, next_sentence_start, options):\n",
    "    \n",
    "    prompt = f\"You are an AI assistant. \\\n",
    "    Based on the activity, input provided, and options provided pick the best option to finish the sentence. \\n \\\n",
    "    In the response, only include the option, don't explain anything \\n \\\n",
    "    \\n\\nContext: {activity}\\n\\n \\\n",
    "    Input: {input_text}\\n\\n \\\n",
    "    Start of the next sentence: {next_sentence_start}\\n\\n \\\n",
    "    \"\n",
    "\n",
    "    prompt += \"Options:\\n\"\n",
    "    for i, option in enumerate(options):\n",
    "\n",
    "        option_string = f\"{i}: {option}\\n\"\n",
    "        prompt += option_string\n",
    "\n",
    "    # print(prompt)\n",
    "    \n",
    "    return invoke_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41dd67c7-b0ab-49db-a60b-c3bb4f0d3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'added 3 cups of water to the rice cooker and turned it on.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "activity = \"cooking rice\"\n",
    "input = \"James Chen is going to cook rice. He went to the rice bucket and put 2 cups of rice in the rice cooker. Then he puts water. \\\n",
    "        \"\n",
    "start = \"After that he\"\n",
    "\n",
    "generate_response(activity, input, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "994db042-ad3c-4cf2-857b-3cda1c76c3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0: washes the rice'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = [\"washes the rice\", \"goes to the store and buys eggs\", \"clay bot rice\", \"cooks the noodle\"]\n",
    "mult_choice_response(activity, input, start, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a6586a-8abc-425c-87c8-1d2400b65f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hellaswag_data = load_dataset(\"Rowan/hellaswag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5cac116-11ca-4b03-b34a-c501604d5edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_label</th>\n",
       "      <th>ctx_a</th>\n",
       "      <th>ctx_b</th>\n",
       "      <th>endings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Removing ice from car</td>\n",
       "      <td>Then, the man writes over the snow covering th...</td>\n",
       "      <td>then</td>\n",
       "      <td>[, the man adds wax to the windshield and cuts...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baking cookies</td>\n",
       "      <td>A female chef in white uniform shows a stack o...</td>\n",
       "      <td>the pans</td>\n",
       "      <td>[contain egg yolks and baking soda., are then ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baking cookies</td>\n",
       "      <td>A female chef in white uniform shows a stack o...</td>\n",
       "      <td>a knife</td>\n",
       "      <td>[is seen moving on a board and cutting out its...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baking cookies</td>\n",
       "      <td>A tray of potatoes is loaded into the oven and...</td>\n",
       "      <td>a large tray of meat</td>\n",
       "      <td>[is placed onto a baked potato., , ls, and pic...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting a haircut</td>\n",
       "      <td>The man in the center is demonstrating a hairs...</td>\n",
       "      <td>the man in the blue shirt</td>\n",
       "      <td>[is standing on the sponge cutting the hair of...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          activity_label                                              ctx_a  \\\n",
       "0  Removing ice from car  Then, the man writes over the snow covering th...   \n",
       "1         Baking cookies  A female chef in white uniform shows a stack o...   \n",
       "2         Baking cookies  A female chef in white uniform shows a stack o...   \n",
       "3         Baking cookies  A tray of potatoes is loaded into the oven and...   \n",
       "4      Getting a haircut  The man in the center is demonstrating a hairs...   \n",
       "\n",
       "                       ctx_b  \\\n",
       "0                       then   \n",
       "1                   the pans   \n",
       "2                    a knife   \n",
       "3       a large tray of meat   \n",
       "4  the man in the blue shirt   \n",
       "\n",
       "                                             endings label  \n",
       "0  [, the man adds wax to the windshield and cuts...     3  \n",
       "1  [contain egg yolks and baking soda., are then ...     3  \n",
       "2  [is seen moving on a board and cutting out its...     3  \n",
       "3  [is placed onto a baked potato., , ls, and pic...     3  \n",
       "4  [is standing on the sponge cutting the hair of...     2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hellaswag_df = pd.DataFrame(hellaswag_data[\"train\"])\n",
    "hellaswag_df.drop(columns=['ind', 'ctx', 'source_id','split','split_type'], inplace = True)\n",
    "hellaswag_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "89eafb8c-6f02-4555-a37b-7bb6f5f0a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    10031\n",
      "3    10021\n",
      "0     9986\n",
      "2     9867\n",
      "Name: count, dtype: int64\n",
      "39905\n"
     ]
    }
   ],
   "source": [
    "print(hellaswag_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0811ab21-5d11-4485-8066-e310db91b4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>activity_label</th>\n",
       "      <th>ctx_a</th>\n",
       "      <th>ctx_b</th>\n",
       "      <th>ctx</th>\n",
       "      <th>endings</th>\n",
       "      <th>source_id</th>\n",
       "      <th>split</th>\n",
       "      <th>split_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>Wakeboarding</td>\n",
       "      <td>A man is being pulled on a water ski as he flo...</td>\n",
       "      <td>he</td>\n",
       "      <td>A man is being pulled on a water ski as he flo...</td>\n",
       "      <td>[mounts the water ski and tears through the wa...</td>\n",
       "      <td>activitynet~v_-5KAycAQlC4</td>\n",
       "      <td>test</td>\n",
       "      <td>indomain</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>Javelin throw</td>\n",
       "      <td>A huge crowd is in the stands in an arena. A m...</td>\n",
       "      <td>several men</td>\n",
       "      <td>A huge crowd is in the stands in an arena. A m...</td>\n",
       "      <td>[are water boarding in a river., are shown thr...</td>\n",
       "      <td>activitynet~v_-fjUWhSM6Hc</td>\n",
       "      <td>test</td>\n",
       "      <td>indomain</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>Javelin throw</td>\n",
       "      <td>The man that threw the javelin celebrates. Ano...</td>\n",
       "      <td>several men</td>\n",
       "      <td>The man that threw the javelin celebrates. Ano...</td>\n",
       "      <td>[run out to where the javelin lands again., th...</td>\n",
       "      <td>activitynet~v_-fjUWhSM6Hc</td>\n",
       "      <td>test</td>\n",
       "      <td>indomain</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>Javelin throw</td>\n",
       "      <td>The second man to throw the javelin and a man ...</td>\n",
       "      <td>the same men</td>\n",
       "      <td>The second man to throw the javelin and a man ...</td>\n",
       "      <td>[do the same action but in different locations...</td>\n",
       "      <td>activitynet~v_-fjUWhSM6Hc</td>\n",
       "      <td>test</td>\n",
       "      <td>indomain</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>Javelin throw</td>\n",
       "      <td>The same men run to the the javelin's landing ...</td>\n",
       "      <td>again</td>\n",
       "      <td>The same men run to the the javelin's landing ...</td>\n",
       "      <td>[, another man does not throw his javelin., th...</td>\n",
       "      <td>activitynet~v_-fjUWhSM6Hc</td>\n",
       "      <td>test</td>\n",
       "      <td>indomain</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind activity_label                                              ctx_a  \\\n",
       "0   14   Wakeboarding  A man is being pulled on a water ski as he flo...   \n",
       "1   71  Javelin throw  A huge crowd is in the stands in an arena. A m...   \n",
       "2   73  Javelin throw  The man that threw the javelin celebrates. Ano...   \n",
       "3   76  Javelin throw  The second man to throw the javelin and a man ...   \n",
       "4   78  Javelin throw  The same men run to the the javelin's landing ...   \n",
       "\n",
       "          ctx_b                                                ctx  \\\n",
       "0            he  A man is being pulled on a water ski as he flo...   \n",
       "1   several men  A huge crowd is in the stands in an arena. A m...   \n",
       "2   several men  The man that threw the javelin celebrates. Ano...   \n",
       "3  the same men  The second man to throw the javelin and a man ...   \n",
       "4         again  The same men run to the the javelin's landing ...   \n",
       "\n",
       "                                             endings  \\\n",
       "0  [mounts the water ski and tears through the wa...   \n",
       "1  [are water boarding in a river., are shown thr...   \n",
       "2  [run out to where the javelin lands again., th...   \n",
       "3  [do the same action but in different locations...   \n",
       "4  [, another man does not throw his javelin., th...   \n",
       "\n",
       "                   source_id split split_type label  \n",
       "0  activitynet~v_-5KAycAQlC4  test   indomain        \n",
       "1  activitynet~v_-fjUWhSM6Hc  test   indomain        \n",
       "2  activitynet~v_-fjUWhSM6Hc  test   indomain        \n",
       "3  activitynet~v_-fjUWhSM6Hc  test   indomain        \n",
       "4  activitynet~v_-fjUWhSM6Hc  test   indomain        "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hellaswag_data['test']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95ef8b6-69f2-433e-9c1b-b533cd1562d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "# Batching can improve this\n",
    "for index, row in hellaswag_df.iterrows():\n",
    "\n",
    "    activity = row['activity_label']\n",
    "    sentences = row['ctx_a']\n",
    "    next_sentence_start = row['ctx_b']\n",
    "    endings = row['endings']\n",
    "    label = row['label']\n",
    "\n",
    "    result = mult_choice_response(activity, sentences, next_sentence_start, endings)\n",
    "    # print(result[0], label)\n",
    "    \n",
    "    if result[0] == label:\n",
    "        correct += 1\n",
    "    if index > 0 and index % 1000 == 0:\n",
    "        print(f\"Current accuracy: {correct/(index + 1)}\");\n",
    "\n",
    "    if index == 3:\n",
    "        break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f5a3517-6b77-4b03-94a2-3b27e79b23c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final accuracy: {correct/len(hellaswag_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac92272-fb6c-4b24-b98c-1ab942aea2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_csv(\"hf://datasets/Idavidrein/gpqa/gpqa_main.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b386952-0a1c-4a43-932b-d53ad6b1e9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Correct Answer</th>\n",
       "      <th>Incorrect Answer 1</th>\n",
       "      <th>Incorrect Answer 2</th>\n",
       "      <th>Incorrect Answer 3</th>\n",
       "      <th>Subdomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A large gene has dozens of exons, of which the...</td>\n",
       "      <td>R-loops</td>\n",
       "      <td>lariat</td>\n",
       "      <td>polyA tail</td>\n",
       "      <td>antisense</td>\n",
       "      <td>Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two quantum states with energies E1 and E2 hav...</td>\n",
       "      <td>10^-4 eV</td>\n",
       "      <td>10^-11 eV</td>\n",
       "      <td>10^-8 eV\\n</td>\n",
       "      <td>10^-9 eV</td>\n",
       "      <td>Physics (general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trans-cinnamaldehyde was treated with methylma...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>Organic Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many of the following compounds exhibit op...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Organic Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A coating is applied to a substrate resulting ...</td>\n",
       "      <td>124°</td>\n",
       "      <td>129°</td>\n",
       "      <td>134°</td>\n",
       "      <td>139°</td>\n",
       "      <td>Chemistry (general)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question Correct Answer  \\\n",
       "0  A large gene has dozens of exons, of which the...        R-loops   \n",
       "1  Two quantum states with energies E1 and E2 hav...       10^-4 eV   \n",
       "2  trans-cinnamaldehyde was treated with methylma...             11   \n",
       "3  how many of the following compounds exhibit op...              4   \n",
       "4  A coating is applied to a substrate resulting ...           124°   \n",
       "\n",
       "  Incorrect Answer 1 Incorrect Answer 2 Incorrect Answer 3  \\\n",
       "0             lariat         polyA tail          antisense   \n",
       "1          10^-11 eV         10^-8 eV\\n           10^-9 eV   \n",
       "2                 10                 12                 14   \n",
       "3                  3                  5                  6   \n",
       "4               129°               134°               139°   \n",
       "\n",
       "             Subdomain  \n",
       "0    Molecular Biology  \n",
       "1    Physics (general)  \n",
       "2    Organic Chemistry  \n",
       "3    Organic Chemistry  \n",
       "4  Chemistry (general)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpqa_dataset = df[['Question', 'Correct Answer', 'Incorrect Answer 1', 'Incorrect Answer 2', 'Incorrect Answer 3', 'Subdomain']]\n",
    "gpqa_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27df7124-ba2a-46dc-bee7-ecab91caec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpqa_answer(subject, question, options):\n",
    "    \n",
    "    prompt = f\"You are a highly knowledgeable AI assistant capable of solving complex scienc and math problems. \\\n",
    "    Please read each question carefully and pick the best option.\\n \\\n",
    "    In the response, only include the option, don't explain anything \\n \\\n",
    "    \\n\\nSubject: {subject}\\n\\n \\\n",
    "    Question: {question}\\n\\n \\\n",
    "    \"\n",
    "\n",
    "    prompt += \"Options:\\n\"\n",
    "    for i, option in enumerate(options):\n",
    "\n",
    "        option_string = f\"{option}\\n\"\n",
    "        prompt += option_string\n",
    "\n",
    "    # print(prompt) \n",
    "    return invoke_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6235c354-bd5a-489d-81b0-e92e8c3c4dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Correct Answer</th>\n",
       "      <th>Incorrect Answer 1</th>\n",
       "      <th>Incorrect Answer 2</th>\n",
       "      <th>Incorrect Answer 3</th>\n",
       "      <th>Subdomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A large gene has dozens of exons, of which the...</td>\n",
       "      <td>R-loops</td>\n",
       "      <td>lariat</td>\n",
       "      <td>polyA tail</td>\n",
       "      <td>antisense</td>\n",
       "      <td>Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two quantum states with energies E1 and E2 hav...</td>\n",
       "      <td>10^-4 eV</td>\n",
       "      <td>10^-11 eV</td>\n",
       "      <td>10^-8 eV\\n</td>\n",
       "      <td>10^-9 eV</td>\n",
       "      <td>Physics (general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trans-cinnamaldehyde was treated with methylma...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>Organic Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many of the following compounds exhibit op...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Organic Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A coating is applied to a substrate resulting ...</td>\n",
       "      <td>124°</td>\n",
       "      <td>129°</td>\n",
       "      <td>134°</td>\n",
       "      <td>139°</td>\n",
       "      <td>Chemistry (general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consider the following metric:\\n\\nds^{2}=\\frac...</td>\n",
       "      <td>+\\infty</td>\n",
       "      <td>0</td>\n",
       "      <td>4\\pi\\left(x^{2}-y^{2}\\right)</td>\n",
       "      <td>4\\pi\\left(x^{2}+y^{2}\\right)</td>\n",
       "      <td>Relativistic Mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aniline is heated with sulfuric acid, forming ...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Organic Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question Correct Answer  \\\n",
       "0  A large gene has dozens of exons, of which the...        R-loops   \n",
       "1  Two quantum states with energies E1 and E2 hav...       10^-4 eV   \n",
       "2  trans-cinnamaldehyde was treated with methylma...             11   \n",
       "3  how many of the following compounds exhibit op...              4   \n",
       "4  A coating is applied to a substrate resulting ...           124°   \n",
       "5  Consider the following metric:\\n\\nds^{2}=\\frac...        +\\infty   \n",
       "6  aniline is heated with sulfuric acid, forming ...              8   \n",
       "\n",
       "  Incorrect Answer 1            Incorrect Answer 2  \\\n",
       "0             lariat                    polyA tail   \n",
       "1          10^-11 eV                    10^-8 eV\\n   \n",
       "2                 10                            12   \n",
       "3                  3                             5   \n",
       "4               129°                          134°   \n",
       "5                  0  4\\pi\\left(x^{2}-y^{2}\\right)   \n",
       "6                  9                             6   \n",
       "\n",
       "             Incorrect Answer 3               Subdomain  \n",
       "0                     antisense       Molecular Biology  \n",
       "1                      10^-9 eV       Physics (general)  \n",
       "2                            14       Organic Chemistry  \n",
       "3                             6       Organic Chemistry  \n",
       "4                          139°     Chemistry (general)  \n",
       "5  4\\pi\\left(x^{2}+y^{2}\\right)  Relativistic Mechanics  \n",
       "6                             7       Organic Chemistry  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpqa_dataset.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c746a8a9-59b4-4930-ac0e-509e84558efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "Accuracy0.16964285714285715\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for index, row in gpqa_dataset.iterrows():\n",
    "    \n",
    "    question = row['Question']\n",
    "    correct = row['Correct Answer']\n",
    "    i1,i2,i3 = row['Incorrect Answer 1'], row['Incorrect Answer 2'], row['Incorrect Answer 3']\n",
    "    options = [correct, i1,i2,i3]\n",
    "    Subdomain = row['Subdomain']\n",
    "    \n",
    "    result = gpqa_answer(Subdomain, question, options)\n",
    "    # print(question)\n",
    "    # print(options)\n",
    "    # print(f\"Result: {result}\\nCorrect:{correct}\")\n",
    "    # print(\"=====================================\\n\")\n",
    "    if result == correct:\n",
    "        x += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "print(x)\n",
    "print(f\"Accuracy: {x/len(gpqa_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4589d6c-24e8-40cf-a057-68a224697ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_batch_response(prompts):\n",
    "\n",
    "    # Create messages for each prompt\n",
    "    batch_messages = [\n",
    "        [{\"role\": \"system\", \"content\": prompt}] for prompt in prompts\n",
    "    ]\n",
    "    \n",
    "    terminators = [\n",
    "        pipe.tokenizer.eos_token_id,\n",
    "        pipe.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    pipe.model.generation_config.pad_token_id = pipe.tokenizer.pad_token_id\n",
    "    \n",
    "    # Process the batch of messages\n",
    "    outputs = pipe(\n",
    "        batch_messages,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=pipe.tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Extract and return responses\n",
    "    responses = [output[0][\"generated_text\"][-1][\"content\"] for output in outputs]\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5aaa5f-011a-47d8-a795-0702649775eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_shot(dataset, column_name, column_value):\n",
    "    # Gives 5 examples of the task given the column name and column\n",
    "    # Dataset should be a pandas dataframe\n",
    "    \n",
    "    alphabet = [chr(i + 65) for i in range(26)]\n",
    "    example_df = dataset[dataset[column_name] == column_value]\n",
    "\n",
    "    questions = example_df['question']\n",
    "    options_list = example_df['options']\n",
    "    subjects = example_df['answer']\n",
    "\n",
    "    five_shot_result = \"Here are some examples of the task you will be doing.\\n\\n\"\n",
    "    for index, (question, options, subject) in enumerate(zip(questions, options_list, subjects)):\n",
    "        \n",
    "        five_shot_result += f\"Example: {index}\\n\"\n",
    "        five_shot_result += f\"Question: {question}\\n\"\n",
    "        prompt += \"Options:\\n\"\n",
    "        for i, option in enumerate(options):\n",
    "    \n",
    "            currLetter = alphabet[i]\n",
    "            option_string = f\"{currLetter}) {option}\\n\"\n",
    "            five_shot_result += option_string\n",
    "            \n",
    "    return five_shot_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83aa485-ee3c-459f-8364-e829cca8cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMLU_Pro_answer(batch):\n",
    "\n",
    "    questions = batch['question']\n",
    "    options_list = batch['options']\n",
    "    subjects = batch['category']\n",
    "\n",
    "    prompts = []\n",
    "    # Creating an array that maps 0 to 'A', 1 to 'B', and so on\n",
    "    alphabet = [chr(i + 65) for i in range(26)]\n",
    "\n",
    "    for subject, question, options in zip(subjects, questions, options_list):\n",
    "    \n",
    "        prompt = f\"\"\"You are a highly knowledgeable expert and are tasked to answer a multiple choice question\\n\n",
    "        \"\"\"\n",
    "        prompt += five_shot(validation_dataset.to_pandas(), 'category', subject)\n",
    "        prompt += f\"\\nQuestion: {question}\\n\"\n",
    "        \n",
    "        prompt += \"Options:\\n\"\n",
    "        for i, option in enumerate(options):\n",
    "    \n",
    "            currLetter = alphabet[i]\n",
    "            option_string = f\"{currLetter}) {option}\\n\"\n",
    "            prompt += option_string\n",
    "    \n",
    "        prompts.append(prompt)\n",
    "    print(prompts[0])\n",
    "    answers = invoke_batch_response(prompts)\n",
    "    return {\"pred_answer\": answers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd24b3-1b7e-44ca-9632-1c2aec9feee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"TIGER-Lab/MMLU-Pro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be1b96-9ba8-4836-9281-3534d065021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = ds[\"test\"]\n",
    "validation_dataset = ds['validation']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5666aa89-da8c-4612-86a9-cf962d61355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a highly knowledgeable expert and are tasked to answer a multiple choice question\n",
      "        \n",
      "Please read each question carefully and pick the best option.\n",
      " \n",
      "        Question: The symmetric group $S_n$ has $\n",
      "actorial{n}$ elements, hence it is not true that $S_{10}$ has 10 elements.\n",
      "Find the characteristic of the ring 2Z.\n",
      "Options:\n",
      "A) 0\n",
      "B) 30\n",
      "C) 3\n",
      "D) 10\n",
      "E) 12\n",
      "F) 50\n",
      "G) 2\n",
      "H) 100\n",
      "I) 20\n",
      "J) 5\n",
      "\n",
      "['A nice question!\\n\\nThe characteristic of a ring is the smallest positive integer n such that a^n = 0 for all a in the ring.\\n\\nIn this case, we are given the ring 2Z, which is the ring of integers modulo 2. Since 2Z is a finite ring, its characteristic is simply the smallest positive integer that generates the zero ideal, which is 2.\\n\\nTherefore, the correct answer is:\\n\\nG) 2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred_answer': ['A nice question!\\n\\nThe characteristic of a ring is the smallest positive integer n such that a^n = 0 for all a in the ring.\\n\\nIn this case, we are given the ring 2Z, which is the ring of integers modulo 2. Since 2Z is a finite ring, its characteristic is simply the smallest positive integer that generates the zero ideal, which is 2.\\n\\nTherefore, the correct answer is:\\n\\nG) 2']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = validation_dataset.to_pandas()\n",
    "\n",
    "# Extract a single example and create a batch\n",
    "single_example = {\n",
    "    'question': [test_df.loc[0, 'question']],\n",
    "    'options': [test_df.loc[0, 'options']],\n",
    "    'category': [test_df.loc[0, 'category']]\n",
    "}\n",
    "\n",
    "MMLU_Pro_answer(single_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb66b33-0523-4388-a70d-d36a9804f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = validation_dataset.remove_columns([\"cot_content\", \"src\", \"answer_index\", \"question_id\"])\n",
    "testing_dataset = testing_dataset.remove_columns([\"cot_content\", \"src\", \"answer_index\", \"question_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b16265-a5ed-45d1-951e-5022bd057745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'options', 'answer', 'category'],\n",
       "    num_rows: 70\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39df6d01-6fd8-46bc-a965-027b28f6b870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function MMLU_Pro_answer at 0x7fa5d908ade0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed5038b2c30498d9a3589d4b9ef7ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py:3161\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3156\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3157\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3158\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3159\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3160\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3161\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3163\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py:3552\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3548\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3549\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3550\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3551\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3552\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3556\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3561\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py:3421\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3420\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3421\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3423\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3424\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3425\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m, in \u001b[0;36mMMLU_Pro_answer\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     26\u001b[0m         prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m option_string\n\u001b[1;32m     28\u001b[0m     prompts\u001b[38;5;241m.\u001b[39mappend(prompt)\n\u001b[0;32m---> 30\u001b[0m answers \u001b[38;5;241m=\u001b[39m \u001b[43minvoke_batch_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m: answers}\n",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m, in \u001b[0;36minvoke_batch_response\u001b[0;34m(prompts)\u001b[0m\n\u001b[1;32m     12\u001b[0m pipe\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Process the batch of messages\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mterminators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Extract and return responses\u001b[39;00m\n\u001b[1;32m     26\u001b[0m responses \u001b[38;5;241m=\u001b[39m [output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:260\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m         chats \u001b[38;5;241m=\u001b[39m [Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs]  \u001b[38;5;66;03m# 🐈 🐈 🐈\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py:1235\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1232\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1233\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[0;32m-> 1235\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1160\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1161\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:349\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1664\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1661\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m inputs_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1663\u001b[0m device \u001b[38;5;241m=\u001b[39m inputs_tensor\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m-> 1664\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_special_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_has_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;66;03m# decoder-only models must use left-padding for batched generation.\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m   1668\u001b[0m     \u001b[38;5;66;03m# If `input_ids` was given, check if the last id in any sequence is `pad_token_id`\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;66;03m# Note: If using, `inputs_embeds` this check does not work, because we want to be more hands-off.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1484\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_special_tokens\u001b[0;34m(self, generation_config, kwargs_has_attention_mask, device)\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(token, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m   1481\u001b[0m bos_token_id \u001b[38;5;241m=\u001b[39m _tensor_or_none(\n\u001b[1;32m   1482\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mbos_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mbos_token_id, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m   1483\u001b[0m )\n\u001b[0;32m-> 1484\u001b[0m eos_token_id \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_or_none\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m pad_token_id \u001b[38;5;241m=\u001b[39m _tensor_or_none(\n\u001b[1;32m   1488\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m   1489\u001b[0m )\n\u001b[1;32m   1490\u001b[0m decoder_start_token_id \u001b[38;5;241m=\u001b[39m _tensor_or_none(\n\u001b[1;32m   1491\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mdecoder_start_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mdecoder_start_token_id, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m   1492\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1479\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_special_tokens.<locals>._tensor_or_none\u001b[0;34m(token_kwargs, token_self, device)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m token\n\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# result_dataset = testing_dataset.map(MMLU_Pro_answer, batched=True, batch_size=32)\n",
    "result_dataset = validation_dataset.map(MMLU_Pro_answer, batched=True, batch_size=32)\n",
    "result_df = result_dataset.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db83f6-20ef-491e-afd8-d3362acade2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebf6d9-e6ad-4f92-9646-a0deebb9db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = result_df['answer'] == result_df['pred_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c1b84f-b26b-41e8-ba93-50434e7c19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4e003-c171-4250-bff9-b1266fe7a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = comparison.mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f73558-71de-48ba-8327-842a98f65176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepeval\n",
      "  Downloading deepeval-0.21.65-py3-none-any.whl.metadata (986 bytes)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from deepeval) (4.66.4)\n",
      "Collecting pytest (from deepeval)\n",
      "  Downloading pytest-8.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.11/site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: typer in /opt/conda/lib/python3.11/site-packages (from deepeval) (0.9.4)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from deepeval) (13.7.1)\n",
      "Collecting protobuf==4.25.1 (from deepeval)\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (from deepeval) (2.7.1)\n",
      "Collecting sentry-sdk (from deepeval)\n",
      "  Downloading sentry_sdk-2.9.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pytest-repeat (from deepeval)\n",
      "  Downloading pytest_repeat-0.9.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pytest-xdist (from deepeval)\n",
      "  Downloading pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting portalocker (from deepeval)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.11/site-packages (from deepeval) (0.1.20)\n",
      "Requirement already satisfied: langchain-core in /opt/conda/lib/python3.11/site-packages (from deepeval) (0.1.52)\n",
      "Requirement already satisfied: langchain-openai in /opt/conda/lib/python3.11/site-packages (from deepeval) (0.1.7)\n",
      "Collecting ragas (from deepeval)\n",
      "  Downloading ragas-0.1.10-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting docx2txt~=0.8 (from deepeval)\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.0.2 in /opt/conda/lib/python3.11/site-packages (from deepeval) (6.11.0)\n",
      "Collecting tenacity~=8.2.3 (from deepeval)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.14.0 (from deepeval)\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.14.0 (from deepeval)\n",
      "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=6.0.2->deepeval) (3.17.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.14.0->deepeval)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.63.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.64.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-sdk<2.0.0,>=1.14.0->deepeval)\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.14.0->deepeval) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain->deepeval) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain->deepeval) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain->deepeval) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from langchain->deepeval) (0.6.6)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /opt/conda/lib/python3.11/site-packages (from langchain->deepeval) (0.0.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from langchain->deepeval) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.11/site-packages (from langchain->deepeval) (0.1.65)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain->deepeval) (1.26.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core->deepeval) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic->deepeval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/conda/lib/python3.11/site-packages (from pydantic->deepeval) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->deepeval) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->deepeval) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->deepeval) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->deepeval) (2024.2.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /opt/conda/lib/python3.11/site-packages (from langchain-openai->deepeval) (1.30.5)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/conda/lib/python3.11/site-packages (from langchain-openai->deepeval) (0.7.0)\n",
      "Collecting iniconfig (from pytest->deepeval)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.5 in /opt/conda/lib/python3.11/site-packages (from pytest->deepeval) (1.5.0)\n",
      "Collecting execnet>=2.1 (from pytest-xdist->deepeval)\n",
      "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from ragas->deepeval) (2.20.0)\n",
      "Collecting pysbd>=0.3.4 (from ragas->deepeval)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ragas->deepeval) (1.6.0)\n",
      "Collecting appdirs (from ragas->deepeval)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->deepeval) (2.18.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.11/site-packages (from typer->deepeval) (8.1.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->deepeval) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->deepeval) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.14.0->deepeval) (1.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (3.10.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (1.3.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai->deepeval) (2024.5.15)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets->ragas->deepeval) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->ragas->deepeval) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets->ragas->deepeval) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->ragas->deepeval) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->ragas->deepeval) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->ragas->deepeval) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets->ragas->deepeval) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->ragas->deepeval) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.11/site-packages (from datasets->ragas->deepeval) (0.23.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai->deepeval) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->ragas->deepeval) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->ragas->deepeval) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->ragas->deepeval) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas->deepeval) (1.16.0)\n",
      "Downloading deepeval-0.21.65-py3-none-any.whl (270 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.4/270.4 kB\u001b[0m \u001b[31m263.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m972.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m94.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m100.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m212.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m470.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.9/339.9 kB\u001b[0m \u001b[31m441.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytest_repeat-0.9.3-py3-none-any.whl (4.2 kB)\n",
      "Downloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m147.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ragas-0.1.10-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.5/91.5 kB\u001b[0m \u001b[31m288.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.9.0-py2.py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m283.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m68.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m64.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=8d6ec7711a903769d0d4c4f952eeebe2883f5ec20dc48113a4e4f9b4b4bd2245\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/0f/0e/7a/3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt, appdirs, tenacity, sentry-sdk, pysbd, protobuf, portalocker, iniconfig, execnet, deprecated, pytest, opentelemetry-proto, opentelemetry-api, pytest-xdist, pytest-repeat, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, ragas, deepeval\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.3.0\n",
      "    Uninstalling tenacity-8.3.0:\n",
      "      Successfully uninstalled tenacity-8.3.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ai21 2.4.0 requires tenacity<9.0.0,>=8.3.0, but you have tenacity 8.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed appdirs-1.4.4 deepeval-0.21.65 deprecated-1.2.14 docx2txt-0.8 execnet-2.1.1 iniconfig-2.0.0 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 portalocker-2.10.1 protobuf-4.25.1 pysbd-0.3.4 pytest-8.2.2 pytest-repeat-0.9.3 pytest-xdist-3.6.1 ragas-0.1.10 sentry-sdk-2.9.0 tenacity-8.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c58afde2-d3f5-4db3-a62d-a938c6f0467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        # Generate text using the pipeline\n",
    "        result = self.pipeline(prompt, do_sample=False)[0]['generated_text']\n",
    "        return result\n",
    "\n",
    "wrapped_model = ModelWrapper(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcce641-1240-4371-8dab-7a1d0c7a889b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
